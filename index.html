<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Speedy-splat accelerates rendering speed by over six times through precisely localizing and pruning Gaussians.">
    <meta name="keywords"
        content="Speedy-Splat, speedysplat, Speedy Splat, speedy splat, speedy-splat, Gaussian Splatting, Gaussian">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives</title>
    <!-- Google tag (gtag.js) -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-KJBVZNV6J3"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-KJBVZNV6J3');
    </script> -->

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css"
        integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.ico">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Speedy-Splat: Fast 3D Gaussian Splatting with Sparse
                            Pixels and Sparse Primitives</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~hanson/">Alex Hanson</a>,</span>
                            <span class="author-block">
                                <a href="https://tuallen.github.io">Allen Tu</a>,</span>
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/people/geng">Geng Lin</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://vasusingla.github.io/">Vasu Singla</a>,
                            </span>

                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~zwicker/">Matthias Zwicker</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">University of Maryland</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <video id="teaser" autoplay muted loop playsinline width="100%">
                    <source src="./static/videos/teaser.mp4" type="video/mp4">
                </video>
                <!-- <h2 class="subtitle has-text-centered">
              <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
              free-viewpoint
              portraits.
            </h2> -->
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            3D Gaussian Splatting (3D-GS) is a recent 3D scene reconstruction technique that enables
                            real-time rendering of novel views by modeling scenes as parametric point clouds of
                            differentiable 3D Gaussians.
                            However, its rendering speed and model size still present bottlenecks, especially in
                            resource-constrained settings.
                        </p>
                        <p>
                            In this paper, we identify and address two key inefficiencies in 3D-GS, achieving
                            substantial improvements in rendering speed, model size, and training time.
                            First, we optimize the rendering pipeline to precisely localize Gaussians in the scene,
                            boosting rendering speed without altering visual fidelity.
                            Second, we introduce a novel pruning technique and integrate it into the training pipeline,
                            significantly reducing model size and training time while further raising rendering speed.
                        </p>
                        <p>
                            Our Speedy-Splat approach combines these techniques to accelerate average rendering speed by
                            a drastic 6.71× across scenes from the Mip-NeRF 360, Tanks & Temples, and Deep Blending
                            datasets with 10.6× fewer primitives than 3D-GS.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method</h2>
                    <div class="content has-text-justified">
                        <p>
                            The rendering speed of 3D Gaussian Splatting (3D-GS) is determined by two primary factors:
                        </p>
                        <ol>
                            <li>The <strong>number of Gaussians allocated to each pixel</strong>, and</li>
                            <li>The <strong>total number of Gaussians</strong> in the scene.</li>
                        </ol>
                        <p>Speedy-Splat introduces methods to address each aspect.</p>
                        <h3 class="title is-4">Number of Gaussians Allocated to Each Pixel</h2>
                            <!-- Figure Section -->
                            <div class="columns is-centered">
                                <div class="column is-one-third">
                                    <figure class="figure-one-third">
                                        <img src="./static/images/3dgs_tile_intersect.png" alt="3DGS tile intersection"
                                            class="figure-image">
                                        <figcaption>(a) 3D Gaussian Splatting </figcaption>
                                    </figure>
                                </div>
                                <div class="column is-one-third">
                                    <figure class="figure-one-third">
                                        <img src="./static/images/bbox_tile_intersect.png" alt="SnugBox tile intersection"
                                            class="figure-image">
                                        <figcaption>(b) SnugBox</figcaption>
                                    </figure>
                                </div>
                                <div class="column is-one-third">
                                    <figure class="figure-one-third">
                                        <img src="./static/images/ellipse_tile_intersect.png" alt="Accutile tile intersection"
                                            class="figure-image">
                                        <figcaption>(c) AccuTile</figcaption>
                                    </figure>
                                </div>
                            </div>
                            <p>
                            <strong>Figure 1: Gaussian tile allocation by method.</strong>

                            (a) 3D Gaussian Splatting allocates a Gaussian to a tile when that tile \(\class{highlight-yellow}{\textbf{intersects}}\) the
                            \(\class{highlight-blue}{\textbf{square}}\) inscribing the \(\class{highlight-purple}{\textbf{circle}}\) with radius
                            \(\left\lceil 3 \sqrt{\lambda_{\max}} \right\rceil\) defined by the maximum eigenvalue of the projected 2D covariance.

                            (b) Our SnugBox method allocates a Gaussian to a tile when that tile \(\class{highlight-yellow}{\textbf{intersects}}\) the tight
                            \(\class{highlight-blue}{\textbf{bounding box}}\) defined by the axis-aligned minima and maxima of the
                            \(\class{highlight-purple}{\textbf{ellipse}}\).

                            (c) Our AccuTile method allocates a Gaussian to a tile only if that tile \(\class{highlight-yellow}{\textbf{intersects}}\) the
                            \(\class{highlight-purple}{\textbf{ellipse}}\) via the AccuTile Algorithm below, which computes the minimum and maximum tiles
                            by iterating over the shorter side of the rectangular tile extent given by SnugBox. In this example, our AccuTile algorithm
                            iterates over the tile rows; the only points that are processed are \(\textbf{$x_{min}$}\), \(\textbf{$x_{max}$}\),
                            <strong>A</strong>, <strong>B</strong>, <strong>C</strong>, and <strong>D</strong>.
                            </p>
                            <p>
                                Gaussian splatting is a tile-based renderer that assigns Gaussians to tiles of pixels
                                by calculating their intersections.
                                As shown in Figure 1.a, the current algorithm for computing Gaussian-tile intersections
                                is overly conservative
                                in that it overestimates the tile extent of Gaussians.
                                We propose two algorithms to increase rendering speed by making exact
                                localizations: <strong>SnugBox</strong> and <strong>AccuTile</strong>.
                            </p>
                            <h4 class="title is-5">SnugBox</h2>
                                <p>
                                    A threshold on \( \alpha_i(p) = \sigma_i g_i(p) \), where \( \sigma_i \) is the
                                    opacity of \(
                                    \mathcal{G}_i \) and \( g_i(p) \) is its value at pixel \( p
                                    \) when it is projected to the image plane, determines the exact pixel exent of
                                    Gaussian
                                    \(\mathcal{G}_i \) as an ellipse.
                                    We compute a tight bounding box — the <strong>SnugBox</strong> presented in Figure
                                    1.b — around this ellipse
                                    by calculating the four points where its first derivative is zero.
                                    After dividing these points by tile size, rounding, and clipping to the image
                                    boundary, we obtain the rectangular tile extent of the Gaussian in constant time.
                                </p>
                            <h4 class="title is-5">AccuTile</h2>
                                <p>
                                    Extending our SnugBox algorithm, we then compute the exact tile intersection of
                                    Gaussian \(\mathcal{G}_i \) by
                                    iterating over the shorter side of the SnugBox tile extent. In each row or
                                    column, we identify the exact tile extent by finding the minimum and maximum
                                    points of the ellipse inside it — all tiles between these points intersect the
                                    ellipse. The insight of our <strong>AccuTile</strong> algorithm, illustrated by
                                    Figure 1.c and provided below, is that
                                    exact Gaussian-tile intersections can be computed efficiently such that only two
                                    points
                                    need to be computed per row or column of the SnugBox.
                                </p>
                                <div>
                                <p>
                                  <b>The AccuTile Algorithm</b>
                                  For simplicity, the algorithm outlined here is applied to the rows of the SnugBox tile extent
                                  bounding box, matching the example in Figure 1.c. In practice, it is applied along the smaller
                                  side of the tile extent. The subscripts \(t\), \(b\), \(l\), and \(r\) represent the <em>top</em>,
                                  <em>bottom</em>, <em>left</em>, and <em>right</em> sides, respectively.
                                </p>
                                <div class="algorithm-container">
                                  <p>
                                      \[
                                      \textbf{Input:}
                                      \]
                                      \[
                                      \begin{aligned}
                                        &\text{Ellipse } \class{highlight-purple}{\mathbf{E}} \\
                                        &\text{Bounding Box } \class{highlight-blue}{\mathbf{B}} \\
                                        &\text{Tile Extent Rectangle } \class{highlight-yellow}{\mathbf{R}}
                                      \end{aligned}
                                      \]
                                      \[
                                      \textbf{Procedure:}
                                      \]
                                      \[
                                      \begin{aligned}
                                      &\text{Tile count } \class{highlight-yellow}{\mathbf{C}} \gets 0 \\
                                      &\class{highlight-yellow}{\text{line}_{\min}} \gets \class{highlight-yellow}{\mathbf{R}_b} \\
                                      &\textbf{if } \class{highlight-yellow}{\text{line}_{\min}} \geq \class{highlight-blue}{\mathbf{B}_b} \textbf{ then } \\
                                      &\quad \class{highlight-purple}{\mathbf{i}_{\min}} \gets \text{Intersections}(
                                            \class{highlight-yellow}{\text{line}_{\min}}, \class{highlight-purple}{\mathbf{E}}) \\

                                      &\textbf{for row } \class{highlight-yellow}{r} \textbf{ in } \class{highlight-yellow}{\mathbf{R}} \textbf{ do } \\
                                      &\quad \class{highlight-yellow}{\text{line}_{\max}} \gets \class{highlight-yellow}{r_t} \\
                                      &\quad \textbf{if } \class{highlight-yellow}{\text{line}_{\max}} \leq \class{highlight-blue}{\mathbf{B}_t} \textbf{ then } \\
                                      &\quad \quad \class{highlight-purple}{\mathbf{i}_{\max}} \gets \text{Intersections}(
                                            \class{highlight-yellow}{\text{line}_{\max}}, \class{highlight-purple}{\mathbf{E}}) \\

                                      &\quad \class{highlight-purple}{e_{\min}} \gets
                                        \begin{cases}
                                          \class{highlight-blue}{\mathbf{B}_l} & \text{if } \class{highlight-blue}{\mathbf{B}_l}
                                                  \text{ in }\class{highlight-yellow}{r} \\
                                          \min(\class{highlight-purple}{\mathbf{i}_{\min}}, \class{highlight-purple}{\mathbf{i}_{\max}}) & \text{otherwise}
                                        \end{cases} \\
                                      &\quad \class{highlight-purple}{e_{\max}} \gets
                                        \begin{cases}
                                          \class{highlight-blue}{\mathbf{B}_r} & \text{if } \class{highlight-blue}{\mathbf{B}_r}
                                                  \text{ in }\class{highlight-yellow}{r} \\
                                          \max(\class{highlight-purple}{\mathbf{i}_{\min}}, \class{highlight-purple}{\mathbf{i}_{\max}}) & \text{otherwise}
                                        \end{cases} \\

                                      &\quad \class{highlight-yellow}{\text{tile}_{\min}}, \class{highlight-yellow}{\text{tile}_{\max}} \gets
                                             \text{Convert}(\class{highlight-purple}{e_{\min}}, \class{highlight-purple}{e_{\max}}) \\
                                      &\quad \class{highlight-yellow}{\mathbf{C}} \gets \class{highlight-yellow}{\mathbf{C}} +
                                              (\class{highlight-yellow}{\text{tile}_{\max}} - \class{highlight-yellow}{\text{tile}_{\min}}) \\

                                      &\quad \text{Process}(\class{highlight-yellow}{\text{tile}_{\min}}, \class{highlight-yellow}{\text{tile}_{\max}}) \\
                                      &\quad \class{highlight-purple}{\mathbf{i}_{\min}} \gets \class{highlight-purple}{\mathbf{i}_{\max}} \\
                                      &\textbf{return } \class{highlight-yellow}{\mathbf{C}}
                                      \end{aligned}
                                      \]
                                  </p>
                                </div>
                        <h3 class="title is-4">Total Number of Gaussians</h2>
                            <p>
                                Recent post-hoc pruning technique <a href="https://pup3dgs.github.io/">PUP 3D-GS</a> [1] finds that approximately 90%
                                of Gaussians can be pruned from pretrained scenes while retaining high
                                visual fidelity. Our <strong>efficient pruning score</strong> identifies a
                                reparameterization of their sensitivity pruning score that improves its
                                memory efficiency by 36×, allowing us to integrate it into the 3D-GS
                                training pipeline via two distinct modalities: <strong>Soft Pruning</strong>
                                and <strong>Hard Pruning</strong>.
                            </p>
                            <h4 class="title is-5">Efficient Pruning Score</h2>
                                <p>
                                    <a href="https://pup3dgs.github.io/">PUP 3D-GS</a> [1] computes a sensitivity pruning score \( U_i \) for each
                                    Gaussian \(
                                    \mathcal{G}_i
                                    \) as the log determinant of the second order approximation of the
                                    reconstruction error with respect to its mean and scaling parameters \(
                                    \mu_i \) and \( s_i \) :
                                    \[
                                    U_i = \log \left| \nabla_{\mu_i,s_i}^2 L_2 \right| = \log \left|
                                    \sum_{\phi
                                    \in \mathcal{P}_{gt}} \nabla_{\mu_i,s_i} I_{\mathcal{G}}(\phi)
                                    \nabla_{\mu_i,s_i} I_{\mathcal{G}}(\phi)^T \right|,
                                    \]
                                    where \( \mathcal{P}_{gt} \) is the set of all training camera poses and
                                    \(
                                    I_{\mathcal{G}}(\phi) \) is the rendered view for pose \( \phi \). This
                                    second order approximation is shown to be exact when the \(L_1 \) error
                                    over
                                    \( \mathcal{P}_{gt} \) is zero.
                                </p>
                                <p>
                                    We update this score by computing it with respect to the projected
                                    Gaussian
                                    values \( g_i \) instead:
                                    \[
                                    \tilde{U}_i = \log \left| \sum_{\phi \in \mathcal{P}_{gt}} \nabla_{g_i}
                                    I_{\mathcal{G}}(\phi) \nabla_{g_i} I_{\mathcal{G}}(\phi)^T \right|.
                                    \]
                                    Because \( g_i \) is a scalar at each pixel and \( \log \) is
                                    monotonically
                                    increasing, we can simplify the score to:

                                    \[
                                    \tilde{U}_i = \sum_{\phi \in \mathcal{P}_{gt}} \nabla_{g_i}
                                    I_{\mathcal{G}}(\phi)^2.
                                    \]

                                    Our <strong>efficient pruning score</strong> reduces the storage
                                    requirement of the sensitivity pruning score by 36× and allows us to integrate it into the 3D-GS training pipeline.

                                <h4 class="title is-5">Soft Pruning and Hard Pruning</h2>
                                    <p>We empirically observe that the \( L_1 \) loss converges quickly
                                        during
                                        training and deploy our efficient pruning score via two modalities:
                                    </p>

                                    <ol>
                                        <li>
                                            <strong>Soft Pruning</strong>, performed during the
                                            densification
                                            stage, and
                                        </li>
                                        <li>
                                            <strong>Hard Pruning</strong>, performed after the
                                            densification stage.
                                        </li>
                                    </ol>
                                    <p>
                                        Together, they reduce the number of Gaussians in the model by
                                        approximately 90%, increasing rendering and training speed while
                                        maintaining image quality.
                                    </p>

                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop content has-text-centered">
                <h2 class="title is-3">Results</h2>
            </div>

            <div class="container is-centered">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-bonsai">
                        <video poster="" id="bonsai" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/bonsai.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-counter">
                        <video poster="" id="counter" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/counter.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-garden">
                        <video poster="" id="garden" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/garden.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-kitchen">
                        <video poster="" id="kitchen" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/kitchen.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-room">
                        <video poster="" id="room" autoplay controls muted loop playsinline height="100%">
                            <source src="static/videos/room.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
    </section>

    <!-- <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>WIP</code></pre>
        </div>
    </section> -->

    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This research is based upon work supported by the Office of the Director of National
                            Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA
                            R\&D Contract No. 140D0423C0076. The views and conclusions contained herein are those of the
                            authors and should not be interpreted as necessarily representing the official policies or
                            endorsements, either expressed or implied, of the ODNI, IARPA, or the U.S. Government. The
                            U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes
                            notwithstanding any copyright annotation thereon. Additional support was provided by ONR
                            MURI program and the AFOSR MURI program. Commercial support was provided by Capital One
                            Bank, the Amazon Research Award program, and Open Philanthropy. Zwicker was additionally
                            supported by the National Science Foundation (IIS-2126407). Goldstein was additionally
                            supported by the National Science Foundation (IIS-2212182) and by the NSF TRAILS Institute
                            (2229885).
                        </p>

                        <p>[1] A. Hanson, A. Tu, V. Singla, M. Jayawardhana, M. Zwicker, and T. Goldstein, "PUP 3D-GS: Principled Uncertainty Pruning for 3D Gaussian Splatting", arXiv, 2024.</p>
                    </div>
                    <div class="content has-text-centered">
                        <p>
                            We thank the authors of <a rel="nerfies"
                                href="https://github.com/nerfies/nerfies.github.io/tree/main">Nerfies</a>
                            for generously open-sourcing the templates used in this website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>